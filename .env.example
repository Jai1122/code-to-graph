# CodeToGraph Configuration Example
# Copy this file to .env and customize as needed

# ===== Neo4j Database Configuration =====
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password123
NEO4J_DATABASE=neo4j

# ===== VLLM Provider Configuration =====
# VLLM is the only supported provider
LLM_PROVIDER=vllm

# VLLM Configuration (for remote inference with API key)
# Replace these with your actual VLLM endpoint details:
LLM_VLLM_BASE_URL=https://your-vllm-endpoint.com
LLM_VLLM_API_KEY=your_api_key_here
LLM_VLLM_MODEL=/app/models/qwen3:14b

# Example for enterprise/VPN environments:
# LLM_VLLM_BASE_URL=https://vllm-inference.company.com
# LLM_VLLM_API_KEY=sk-your-actual-api-key-from-admin
# LLM_VLLM_MODEL=/app/models/qwen3:14b

# General LLM Settings
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=120

# ===== Processing Configuration =====
PROCESSING_CHUNK_STRATEGY=hybrid
PROCESSING_MAX_CHUNK_SIZE=100
PROCESSING_MAX_MEMORY_GB=16
PROCESSING_ENABLE_TREE_SITTER=true
PROCESSING_ENABLE_JOERN=true
PROCESSING_JOERN_HEAP_SIZE=8G

# ===== Visualization Configuration =====
VIZ_HOST=localhost
VIZ_PORT=8080
VIZ_DEBUG=false
VIZ_MAX_NODES_PER_VIEW=1000

# ===== Debug Settings =====
DEBUG=false
LOG_LEVEL=INFO