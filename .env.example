# CodeToGraph Configuration Example
# Copy this file to .env and customize as needed

# ===== Neo4j Database Configuration =====
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password123
NEO4J_DATABASE=neo4j

# ===== LLM Provider Configuration =====
# Choose your provider: ollama, vllm
LLM_PROVIDER=ollama

# OLLAMA Configuration (for local inference)
LLM_OLLAMA_BASE_URL=http://localhost:11434
LLM_OLLAMA_MODEL=qwen3:1.7b

# VLLM Configuration (for remote inference with API key)
LLM_VLLM_BASE_URL=https://vllm.com
LLM_VLLM_API_KEY=your_api_key_here
LLM_VLLM_MODEL=/app/models/qwen3:14b

# OpenAI Configuration (alternative provider)
LLM_OPENAI_API_KEY=your_openai_api_key_here
LLM_OPENAI_MODEL=gpt-4o

# General LLM Settings
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=120

# ===== Processing Configuration =====
PROCESSING_CHUNK_STRATEGY=hybrid
PROCESSING_MAX_CHUNK_SIZE=100
PROCESSING_MAX_MEMORY_GB=16
PROCESSING_ENABLE_TREE_SITTER=true
PROCESSING_ENABLE_JOERN=true
PROCESSING_JOERN_HEAP_SIZE=8G

# ===== Visualization Configuration =====
VIZ_HOST=localhost
VIZ_PORT=8080
VIZ_DEBUG=false
VIZ_MAX_NODES_PER_VIEW=1000

# ===== Debug Settings =====
DEBUG=false
LOG_LEVEL=INFO